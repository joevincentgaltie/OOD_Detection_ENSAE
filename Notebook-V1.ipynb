{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns \n",
    "import tqdm \n",
    "from typing import List \n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Todd library to implement scorers\n",
    "\n",
    "from Todd import (\n",
    "    ScorerType, \n",
    "    MahalanobisScorer, \n",
    "    CosineProjectionScorer, \n",
    "    DataDepthScorer, \n",
    ")\n",
    "\n",
    "from toddbenchmark.classification_datasets import (prep_model, prep_dataset, load_sst2)\n",
    "from toddbenchmark.utils_classification import evaluate_dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = prep_model(\"echarlaix/bert-base-uncased-sst2-acc91.1-d37-hybrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset glue (/Users/joevincentgaltie/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1fae26b91e64290a75c6339f4acdd90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/Users/joevincentgaltie/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "504868e459b64e4db3c1975191af67b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config_sst2=  {\"label\": 2, \"metric\": \"sst2\", \"keys\": (\"text\", None)}\n",
    "config_imdb = {\"label\": 2, \"metric\": \"sst2\", \"keys\": (\"text\", None)}\n",
    "\n",
    "in_dataset = prep_dataset(\"sst2\", config_sst2, tokenizer=tokenizer, train_max_size=0, validation_max_size=1000, test_max_size=100)\n",
    "out_dataset = prep_dataset(\"imdb\", config_imdb, tokenizer=tokenizer, train_max_size=1000, validation_max_size=1000,test_max_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_val = in_dataset[1]\n",
    "in_test = in_dataset[2]\n",
    "out_test = out_dataset[2]\n",
    "\n",
    "\n",
    "in_val_loader = DataLoader(in_val, shuffle=False, batch_size=4)\n",
    "in_test_loader = DataLoader(in_test, shuffle=False, batch_size=4)\n",
    "out_test_loader = DataLoader(out_test, shuffle=False, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list, {})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maha_detector = MahalanobisScorer(layers=[-1])\n",
    "maha_detector.accumulated_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Todd.featuresscorers.MahalanobisScorer"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(maha_detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x1375c1e80>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'labels'],\n",
       "    num_rows: 872\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 218/218 [00:29<00:00,  7.36it/s]\n"
     ]
    }
   ],
   "source": [
    "def prepare_embeddings(scorer, loader):\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader):\n",
    "            inputs = tokenizer(\n",
    "                batch[\"text\"], padding=True, truncation=True, return_tensors=\"pt\"\n",
    "            )\n",
    "            output = model(\n",
    "                **inputs,\n",
    "                #return_dict_in_generate=True,\n",
    "                output_hidden_states=True,\n",
    "                #output_scores=True,\n",
    "            )\n",
    "            output['encoder_hidden_states'] = output['hidden_states']\n",
    "\n",
    "            scorer.accumulate(output,y=None)\n",
    "\n",
    "prepare_embeddings(maha_detector, loader=in_val_loader)\n",
    "maha_detector.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([419778.5000, 377216.8438, 325469.4375, 466846.4375])\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1185780.5000, 1372989.5000, 1780022.8750, 1078624.8750])\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def eval_loader(loader):\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader):\n",
    "            inputs = tokenizer(\n",
    "                batch[\"text\"], padding=True, truncation=True, return_tensors=\"pt\"\n",
    "            )\n",
    "            output = model(\n",
    "                **inputs,\n",
    "                #return_dict_in_generate=True,\n",
    "                output_hidden_states=True,\n",
    "                #output_scores=True,\n",
    "            )\n",
    "\n",
    "            output['encoder_hidden_states'] = output['hidden_states']\n",
    "            \n",
    "            print(maha_detector(output))\n",
    "            break\n",
    "\n",
    "\n",
    "print(eval_loader(in_test_loader))\n",
    "print(eval_loader(out_test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on the in-distribution training set\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'MahalanobisScorer' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEvaluating on the in-distribution training set\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m records_in_train \u001b[39m=\u001b[39m evaluate_dataloader(\n\u001b[1;32m      4\u001b[0m     model,\n\u001b[1;32m      5\u001b[0m     in_val_loader,\n\u001b[1;32m      6\u001b[0m     tokenizer,\n\u001b[1;32m      7\u001b[0m     maha_detector\n\u001b[1;32m      8\u001b[0m )\n",
      "File \u001b[0;32m~/ood4/toddbenchmark/utils_classification.py:100\u001b[0m, in \u001b[0;36mevaluate_dataloader\u001b[0;34m(model, data_loader, tokenizer, detectors, energy_temperature)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate_dataloader\u001b[39m(\n\u001b[1;32m     93\u001b[0m         model,\n\u001b[1;32m     94\u001b[0m         data_loader: DataLoader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     98\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, List]:\n\u001b[1;32m     99\u001b[0m     \u001b[39m# Initialize the scores dictionary\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m     records: Dict[\u001b[39mstr\u001b[39m, List] \u001b[39m=\u001b[39m {\n\u001b[1;32m    101\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mdetector\u001b[39m}\u001b[39;00m\u001b[39m+\u001b[39m\u001b[39m{\u001b[39;00mscore_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m: []\n\u001b[1;32m    102\u001b[0m         \u001b[39mfor\u001b[39;00m detector \u001b[39min\u001b[39;00m detectors\n\u001b[1;32m    103\u001b[0m         \u001b[39mfor\u001b[39;00m score_name \u001b[39min\u001b[39;00m detector\u001b[39m.\u001b[39mscore_names\n\u001b[1;32m    104\u001b[0m     }\n\u001b[1;32m    106\u001b[0m     records[\u001b[39m\"\u001b[39m\u001b[39mmsp\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m []\n\u001b[1;32m    107\u001b[0m     records[\u001b[39m\"\u001b[39m\u001b[39menergy\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m []\n",
      "\u001b[0;31mTypeError\u001b[0m: 'MahalanobisScorer' object is not iterable"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating on the in-distribution training set\")\n",
    "\n",
    "records_in_train = evaluate_dataloader(\n",
    "    model,\n",
    "    in_val_loader,\n",
    "    tokenizer,\n",
    "    maha_detector\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MahalanobisScorer' object has no attribute 'accumulated_embeddings'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m maha_detector\u001b[39m.\u001b[39;49maccumulated_embeddings\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MahalanobisScorer' object has no attribute 'accumulated_embeddings'"
     ]
    }
   ],
   "source": [
    "maha_detector.accumulated_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "inputs = tokenizer(\n",
    "               next(iter(in_val_loader))[\"text\"], padding=True, truncation=True, return_tensors=\"pt\"\n",
    "            )\n",
    "\n",
    "output = model(\n",
    "                **inputs,\n",
    "                #return_dict_in_generate=True,\n",
    "                output_hidden_states=True,\n",
    "                #output_scores=True,\n",
    "            )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-3.5209,  4.5214],\n",
       "        [ 2.4283, -2.5945],\n",
       "        [-3.1178,  3.9888],\n",
       "        [-2.7755,  3.6769]], grad_fn=<AddmmBackward0>), hidden_states=(tensor([[[ 0.1560, -0.2660, -0.3172,  ..., -0.0048,  0.0145,  0.1522],\n",
       "         [-0.4534, -0.0029, -0.0558,  ...,  0.7296,  0.9141,  0.1591],\n",
       "         [-0.7016,  0.2778,  0.2457,  ...,  0.4870,  0.6775, -1.1272],\n",
       "         ...,\n",
       "         [ 0.1444, -0.2958, -0.2512,  ...,  0.1014, -0.3191,  0.0963],\n",
       "         [-0.1005, -0.3642, -0.0352,  ..., -0.1397, -0.1140,  0.0108],\n",
       "         [-0.0458, -0.4816, -0.0440,  ..., -0.3120, -0.2293, -0.0493]],\n",
       "\n",
       "        [[ 0.1560, -0.2660, -0.3172,  ..., -0.0048,  0.0145,  0.1522],\n",
       "         [-0.6175, -0.2491,  0.1479,  ...,  0.3129,  0.4923,  0.2938],\n",
       "         [ 0.2888,  0.8513,  0.1758,  ..., -0.0930,  0.8163, -0.0227],\n",
       "         ...,\n",
       "         [ 0.1444, -0.2958, -0.2512,  ...,  0.1014, -0.3191,  0.0963],\n",
       "         [-0.1005, -0.3642, -0.0352,  ..., -0.1397, -0.1140,  0.0108],\n",
       "         [-0.0458, -0.4816, -0.0440,  ..., -0.3120, -0.2293, -0.0493]],\n",
       "\n",
       "        [[ 0.1560, -0.2660, -0.3172,  ..., -0.0048,  0.0145,  0.1522],\n",
       "         [-0.6299, -0.2603, -0.2503,  ...,  0.0807,  0.9459,  0.0193],\n",
       "         [-0.5074,  0.0683, -1.0561,  ...,  0.7365,  1.4454,  0.2677],\n",
       "         ...,\n",
       "         [ 0.1444, -0.2958, -0.2512,  ...,  0.1014, -0.3191,  0.0963],\n",
       "         [-0.1005, -0.3642, -0.0352,  ..., -0.1397, -0.1140,  0.0108],\n",
       "         [-0.0458, -0.4816, -0.0440,  ..., -0.3120, -0.2293, -0.0493]],\n",
       "\n",
       "        [[ 0.1560, -0.2660, -0.3172,  ..., -0.0048,  0.0145,  0.1522],\n",
       "         [-0.4784,  0.5362,  0.0761,  ..., -0.0226,  0.6063, -0.5658],\n",
       "         [-0.1213,  0.0660,  0.0943,  ..., -0.3101,  1.3124, -0.0196],\n",
       "         ...,\n",
       "         [-0.5067,  0.3329,  0.4178,  ...,  0.2395,  0.5869,  0.4460],\n",
       "         [-0.4969,  0.4805,  0.0188,  ...,  0.2072,  0.6569,  0.4019],\n",
       "         [-0.5171,  0.0767,  0.1305,  ..., -0.7185,  0.1160, -0.2946]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.1386, -0.0943, -0.1236,  ..., -0.0149,  0.0236,  0.0739],\n",
       "         [-0.4413, -0.2936,  0.0399,  ...,  0.7555,  0.6516, -0.0651],\n",
       "         [-1.3479,  0.2791,  0.2836,  ...,  0.3201,  0.5494, -1.6503],\n",
       "         ...,\n",
       "         [-0.0488,  0.2082,  0.3046,  ...,  0.2434, -0.2678, -0.1393],\n",
       "         [-0.3520,  0.1247,  0.5563,  ..., -0.0676, -0.0844, -0.2632],\n",
       "         [-0.2895,  0.0789,  0.5229,  ..., -0.2055, -0.2187, -0.3202]],\n",
       "\n",
       "        [[ 0.1768, -0.1430, -0.1309,  ..., -0.0497,  0.0806,  0.0836],\n",
       "         [-0.6862, -0.4881,  0.0642,  ...,  0.0731,  0.8334,  0.8339],\n",
       "         [ 0.4864,  0.4606, -0.0372,  ..., -0.2030,  0.9064, -0.3878],\n",
       "         ...,\n",
       "         [ 0.0938,  0.1327,  0.2889,  ...,  0.1403, -0.1683, -0.1309],\n",
       "         [-0.1963,  0.0430,  0.5472,  ..., -0.1841,  0.0187, -0.2724],\n",
       "         [-0.1497, -0.0192,  0.4918,  ..., -0.3304, -0.1206, -0.3395]],\n",
       "\n",
       "        [[ 0.1481, -0.1015, -0.1208,  ..., -0.0420,  0.0743,  0.1119],\n",
       "         [-1.0354, -0.5855, -0.1553,  ...,  0.0463,  1.3470,  0.2449],\n",
       "         [-0.1420,  0.2676, -1.1980,  ...,  0.4532,  1.1747,  0.0022],\n",
       "         ...,\n",
       "         [ 0.0431,  0.1006,  0.3202,  ...,  0.1582, -0.0931, -0.0286],\n",
       "         [-0.2730,  0.0173,  0.5390,  ..., -0.1579,  0.0714, -0.1593],\n",
       "         [-0.1897, -0.0175,  0.4926,  ..., -0.3194, -0.0641, -0.2149]],\n",
       "\n",
       "        [[ 0.1564, -0.0915, -0.1126,  ...,  0.0252,  0.0345,  0.0714],\n",
       "         [-0.4571,  0.4078, -0.0534,  ...,  0.1493,  0.4263, -1.3090],\n",
       "         [ 0.0103,  0.5759, -0.2970,  ...,  0.1797,  1.4592, -0.4427],\n",
       "         ...,\n",
       "         [ 0.0181,  0.4130,  0.7765,  ...,  0.0566,  0.3400,  0.4727],\n",
       "         [-0.5912,  0.4902,  0.0945,  ...,  0.1243,  0.3119,  0.2070],\n",
       "         [-0.3185,  0.0846,  0.0954,  ..., -0.3544,  0.2659, -0.2825]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 1.1484e-01, -1.2000e-01, -1.1676e-01,  ..., -7.4288e-02,\n",
       "          -3.7520e-02,  7.8321e-02],\n",
       "         [-2.4288e-01, -1.1184e-01,  2.5687e-01,  ...,  7.8932e-01,\n",
       "           6.9151e-01,  2.4416e-01],\n",
       "         [-1.1724e+00, -4.9105e-01,  3.5817e-01,  ...,  2.8939e-01,\n",
       "           4.6774e-01, -1.2749e+00],\n",
       "         ...,\n",
       "         [-1.6952e-01,  1.5654e-01,  4.7129e-01,  ...,  2.9094e-01,\n",
       "          -3.1330e-01, -2.3719e-02],\n",
       "         [-6.3867e-01,  2.0556e-02,  8.3722e-01,  ..., -1.8004e-01,\n",
       "          -4.0588e-03, -1.9640e-01],\n",
       "         [-5.6071e-01, -9.3599e-02,  7.8014e-01,  ..., -4.0392e-01,\n",
       "          -1.3247e-01, -3.0323e-01]],\n",
       "\n",
       "        [[ 1.3667e-01, -1.3792e-01, -1.4020e-01,  ..., -9.2461e-02,\n",
       "          -1.9990e-02,  7.2953e-02],\n",
       "         [-1.8776e-01, -2.1439e-01,  4.6685e-01,  ..., -8.0597e-01,\n",
       "           5.7820e-01,  1.0764e+00],\n",
       "         [ 8.3843e-02,  2.7432e-01,  1.9059e-02,  ..., -5.8244e-01,\n",
       "           1.5974e+00, -1.0340e+00],\n",
       "         ...,\n",
       "         [ 5.6431e-02,  1.3254e-01,  4.9959e-01,  ...,  1.5584e-01,\n",
       "          -2.0956e-01, -2.5161e-02],\n",
       "         [-4.0160e-01,  1.0146e-03,  8.6189e-01,  ..., -3.1007e-01,\n",
       "           7.0312e-02, -2.2492e-01],\n",
       "         [-2.9961e-01, -1.9792e-01,  7.3155e-01,  ..., -5.3189e-01,\n",
       "          -5.9040e-02, -4.1693e-01]],\n",
       "\n",
       "        [[ 9.1815e-02, -1.4325e-01, -8.6607e-02,  ..., -1.1566e-01,\n",
       "           8.4258e-03,  1.0996e-01],\n",
       "         [-1.3263e+00, -8.6073e-01,  7.8293e-01,  ..., -1.1203e-01,\n",
       "           1.5716e+00,  6.3688e-02],\n",
       "         [-3.9593e-01, -1.0474e-01, -1.1355e+00,  ...,  9.3958e-02,\n",
       "           1.3406e+00,  4.1315e-01],\n",
       "         ...,\n",
       "         [ 3.6494e-03,  6.6718e-03,  5.9558e-01,  ...,  7.3148e-02,\n",
       "          -1.9503e-01,  8.6296e-02],\n",
       "         [-4.0071e-01, -9.9074e-02,  9.0777e-01,  ..., -4.4806e-01,\n",
       "           9.9342e-03, -1.7342e-01],\n",
       "         [-2.7614e-01, -1.6912e-01,  8.7897e-01,  ..., -6.5916e-01,\n",
       "          -1.1031e-01, -2.8396e-01]],\n",
       "\n",
       "        [[ 1.5336e-01, -1.0403e-01, -5.7548e-02,  ...,  5.8244e-04,\n",
       "          -2.0692e-02,  2.5639e-02],\n",
       "         [-3.2566e-01,  4.7285e-01, -4.8240e-02,  ...,  9.7213e-02,\n",
       "           8.2809e-02, -1.3825e+00],\n",
       "         [ 3.3991e-02,  4.8323e-02, -3.9144e-01,  ...,  5.4287e-01,\n",
       "           1.5119e+00, -8.0023e-01],\n",
       "         ...,\n",
       "         [ 4.2564e-01,  4.7227e-01,  5.4813e-01,  ...,  2.4231e-01,\n",
       "           1.7570e-01,  3.4825e-01],\n",
       "         [-4.4601e-01,  3.4862e-01,  4.7114e-01,  ...,  2.3454e-02,\n",
       "           2.6101e-01,  1.5142e-01],\n",
       "         [-4.1601e-02, -1.8176e-02,  2.2085e-01,  ..., -3.3550e-01,\n",
       "           1.5172e-01, -3.9958e-01]]], grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.0964, -0.1229, -0.1695,  ..., -0.1292, -0.0640,  0.0915],\n",
       "         [-0.2135, -0.2373, -0.1814,  ...,  0.6137,  0.6585,  0.0051],\n",
       "         [-0.9098, -0.6293,  0.7303,  ...,  0.3261,  0.8649, -1.1043],\n",
       "         ...,\n",
       "         [-0.1298,  0.1762,  0.3778,  ..., -0.0308, -0.2468,  0.0333],\n",
       "         [-0.5301, -0.1648,  0.6444,  ..., -0.5057,  0.1081, -0.0730],\n",
       "         [-0.6341, -0.2276,  0.6885,  ..., -0.3464, -0.1424, -0.0879]],\n",
       "\n",
       "        [[ 0.1098, -0.1121, -0.2536,  ..., -0.1409, -0.0691,  0.1298],\n",
       "         [-0.3815, -0.2937,  0.3802,  ..., -0.3111,  0.2499,  0.5686],\n",
       "         [ 0.3411,  0.7106,  0.1374,  ..., -0.6643,  1.2787, -0.9159],\n",
       "         ...,\n",
       "         [ 0.0210,  0.0210,  0.3170,  ..., -0.2339, -0.1660,  0.3426],\n",
       "         [-0.3873, -0.0915,  0.6650,  ..., -0.4512,  0.0374,  0.0702],\n",
       "         [-0.3327, -0.2448,  0.5537,  ..., -0.5856, -0.3823, -0.2544]],\n",
       "\n",
       "        [[ 0.0613, -0.1720, -0.1549,  ..., -0.1825,  0.0029,  0.1479],\n",
       "         [-1.4143, -0.3902,  0.8493,  ..., -0.0810,  1.0260, -0.1793],\n",
       "         [-0.7509, -0.4119, -0.9003,  ...,  0.5717,  0.7807,  0.3559],\n",
       "         ...,\n",
       "         [-0.0055, -0.0277,  0.3905,  ..., -0.3029, -0.0706,  0.2455],\n",
       "         [-0.3210, -0.0032,  0.6904,  ..., -0.6401,  0.0996, -0.1725],\n",
       "         [-0.2634, -0.1468,  0.6904,  ..., -0.7238, -0.1763, -0.1896]],\n",
       "\n",
       "        [[ 0.1151, -0.1097, -0.1623,  ..., -0.0185, -0.0610,  0.0311],\n",
       "         [-0.4662,  0.3575,  0.1408,  ...,  0.3081,  0.0645, -1.4546],\n",
       "         [-0.2444,  0.0425, -0.5061,  ...,  0.2839,  1.1870, -0.6380],\n",
       "         ...,\n",
       "         [ 0.7165,  0.6222,  0.3073,  ..., -0.0998,  0.3320, -0.1162],\n",
       "         [-0.5963,  0.3861,  0.3062,  ..., -0.1943,  0.0153, -0.3197],\n",
       "         [-0.0451, -0.0364,  0.0830,  ..., -0.0460,  0.0314, -0.0976]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.1023, -0.3950, -0.4414,  ..., -0.0944, -0.2741,  0.3080],\n",
       "         [-0.2494, -0.7079,  0.0037,  ...,  0.6248,  0.0426, -0.3406],\n",
       "         [-1.3031, -0.9462,  1.1083,  ...,  0.1050,  0.5083, -0.7887],\n",
       "         ...,\n",
       "         [-0.2735,  0.0148,  0.4391,  ..., -0.0748, -0.4714,  0.0979],\n",
       "         [-0.7241, -0.2530,  0.6890,  ..., -0.6196, -0.1044,  0.0294],\n",
       "         [-0.9076, -0.4529,  0.7808,  ..., -0.4775, -0.4127,  0.0279]],\n",
       "\n",
       "        [[ 0.1791, -0.3634, -0.5068,  ..., -0.0957, -0.2036,  0.3011],\n",
       "         [-0.5784, -0.4097,  0.3454,  ..., -0.3656,  0.1780,  0.4601],\n",
       "         [-0.0903,  0.5864,  0.0989,  ..., -0.9022,  0.6899, -0.9694],\n",
       "         ...,\n",
       "         [-0.0803, -0.1226,  0.3498,  ..., -0.2716, -0.2973,  0.4291],\n",
       "         [-0.5408, -0.2572,  0.5145,  ..., -0.4106, -0.2474,  0.2604],\n",
       "         [-0.4942, -0.3287,  0.5582,  ..., -0.7082, -0.5778, -0.1794]],\n",
       "\n",
       "        [[ 0.1241, -0.4279, -0.3600,  ..., -0.1841, -0.1424,  0.3621],\n",
       "         [-1.5994, -1.0400,  0.6647,  ...,  0.3563,  0.8369,  0.3374],\n",
       "         [-0.3643, -0.8890, -0.6751,  ...,  0.3187,  0.5832,  0.2461],\n",
       "         ...,\n",
       "         [-0.0656, -0.0716,  0.5623,  ..., -0.3668, -0.1034,  0.3519],\n",
       "         [-0.4517,  0.0099,  0.8185,  ..., -0.6997, -0.1014, -0.0918],\n",
       "         [-0.5009, -0.2394,  0.8300,  ..., -0.8743, -0.3398, -0.1358]],\n",
       "\n",
       "        [[ 0.1692, -0.2831, -0.4759,  ..., -0.0306, -0.2452,  0.1926],\n",
       "         [-0.7193,  0.1479,  0.2064,  ..., -0.2841, -0.2808, -1.7046],\n",
       "         [ 0.0032, -0.4348, -0.3951,  ...,  0.0449,  1.1508, -0.7531],\n",
       "         ...,\n",
       "         [ 0.8096,  0.2567,  0.1899,  ..., -0.0989,  0.5073,  0.1201],\n",
       "         [-0.5321,  0.3420,  0.3610,  ..., -0.1776, -0.2646, -0.2385],\n",
       "         [-0.0348, -0.0152,  0.0159,  ...,  0.0192, -0.0040, -0.0223]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.1419, -0.2197, -0.7348,  ..., -0.3044, -0.3051,  0.4828],\n",
       "         [-0.2752, -0.5554, -0.0882,  ...,  0.8566, -0.0724, -0.5996],\n",
       "         [-1.0885, -0.7752,  0.5232,  ..., -0.0328,  0.3049, -0.9338],\n",
       "         ...,\n",
       "         [-0.2492,  0.1468,  0.2456,  ...,  0.0567, -0.4109,  0.1325],\n",
       "         [-0.6653, -0.0850,  0.4106,  ..., -0.3821, -0.1373,  0.0237],\n",
       "         [-0.8738, -0.3519,  0.5521,  ..., -0.1734, -0.3497,  0.0520]],\n",
       "\n",
       "        [[-0.0860, -0.1928, -0.7130,  ..., -0.3265, -0.3140,  0.5024],\n",
       "         [-0.3334, -0.6069,  0.0961,  ..., -0.4639, -0.3906,  0.4130],\n",
       "         [-0.2666,  0.8974,  0.2834,  ..., -0.6219,  0.9684, -1.1756],\n",
       "         ...,\n",
       "         [-0.0201,  0.0734,  0.1420,  ..., -0.0793, -0.2999,  0.5578],\n",
       "         [-0.4431, -0.1361,  0.3075,  ..., -0.0218, -0.3003,  0.3659],\n",
       "         [-0.4138, -0.1245,  0.2528,  ..., -0.4039, -0.5189, -0.0812]],\n",
       "\n",
       "        [[-0.0747, -0.2909, -0.6682,  ..., -0.3967, -0.1930,  0.4912],\n",
       "         [-0.7265, -1.5012,  0.3873,  ...,  0.3377,  0.9898,  0.1147],\n",
       "         [-0.7372, -1.3407, -0.8206,  ...,  0.4182,  0.3555,  0.2500],\n",
       "         ...,\n",
       "         [ 0.0269,  0.0167,  0.3558,  ..., -0.1863, -0.0577,  0.3588],\n",
       "         [-0.3630,  0.1540,  0.4877,  ..., -0.4833, -0.0317, -0.1318],\n",
       "         [-0.3789, -0.1911,  0.5270,  ..., -0.5955, -0.2362, -0.1889]],\n",
       "\n",
       "        [[-0.0590, -0.2121, -0.6562,  ..., -0.2607, -0.3332,  0.3621],\n",
       "         [-0.6711,  0.0880, -0.3325,  ..., -0.4187, -0.2403, -1.9201],\n",
       "         [ 0.4437, -0.5493, -0.6226,  ..., -0.7029,  0.9153, -1.2584],\n",
       "         ...,\n",
       "         [ 0.8724,  0.4838, -0.2240,  ..., -0.2441,  0.6400,  0.3798],\n",
       "         [-0.7179,  0.3135,  0.3641,  ..., -0.0655, -0.1530, -0.2644],\n",
       "         [-0.0187, -0.0045, -0.0032,  ...,  0.0425, -0.0270, -0.0350]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.4391, -0.1602, -1.0338,  ..., -0.3092, -0.3750,  0.6426],\n",
       "         [ 0.2581, -0.6102, -0.1116,  ...,  0.7628,  0.3154, -0.3282],\n",
       "         [-0.9010, -0.6228,  0.7668,  ..., -0.0196,  0.8913, -0.7805],\n",
       "         ...,\n",
       "         [-0.4986,  0.0848,  0.4332,  ..., -0.0367, -0.3705,  0.0193],\n",
       "         [-0.8616,  0.0324,  0.4964,  ..., -0.4062, -0.1805, -0.0855],\n",
       "         [-1.1108, -0.2327,  0.8222,  ..., -0.1002, -0.3291, -0.0936]],\n",
       "\n",
       "        [[-0.3609, -0.0251, -1.0970,  ..., -0.6321, -0.4484,  0.7067],\n",
       "         [-0.1113, -0.1256,  0.3670,  ..., -0.3661,  0.1558,  0.2549],\n",
       "         [-0.5564,  0.8956,  0.3356,  ..., -0.7311,  0.8462, -1.1702],\n",
       "         ...,\n",
       "         [-0.3934,  0.1631,  0.2789,  ..., -0.3330, -0.2542,  0.4528],\n",
       "         [-0.7790, -0.0243,  0.2800,  ..., -0.1228, -0.2350,  0.3090],\n",
       "         [-0.6439,  0.1329,  0.3827,  ..., -0.6474, -0.3974, -0.2582]],\n",
       "\n",
       "        [[-0.2948, -0.3119, -0.8997,  ..., -0.6230, -0.2385,  0.6216],\n",
       "         [-0.5594, -1.3770,  0.8486,  ..., -0.4308,  0.9390, -0.1555],\n",
       "         [-0.9233, -1.2334, -0.5528,  ..., -0.0776,  0.4048,  0.0508],\n",
       "         ...,\n",
       "         [-0.1907,  0.0263,  0.7311,  ..., -0.3954,  0.0668,  0.1886],\n",
       "         [-0.4603,  0.2606,  0.6664,  ..., -0.6124, -0.1132, -0.2873],\n",
       "         [-0.5869, -0.0984,  0.8387,  ..., -0.8113, -0.2507, -0.3170]],\n",
       "\n",
       "        [[-0.0942, -0.1388, -1.0950,  ..., -0.4001, -0.3740,  0.5210],\n",
       "         [-0.4538,  0.3301, -0.3368,  ..., -0.2031, -0.2706, -1.7863],\n",
       "         [ 0.3119, -0.2908, -0.5398,  ..., -0.4067,  0.7003, -1.2549],\n",
       "         ...,\n",
       "         [ 0.6799,  0.8083,  0.2120,  ..., -0.1042,  1.1119,  0.1753],\n",
       "         [-0.7379,  0.5950, -0.0832,  ..., -0.1812, -0.2189,  0.2982],\n",
       "         [ 0.0251,  0.0473, -0.0422,  ...,  0.0309, -0.0204, -0.0250]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.4613, -0.4245, -1.0783,  ..., -0.6734, -0.3723,  0.3767],\n",
       "         [ 0.0996, -0.9020, -0.1813,  ...,  0.2997,  0.0108, -0.4903],\n",
       "         [-0.8121, -0.6011,  0.8368,  ..., -0.2507,  0.8558, -0.9715],\n",
       "         ...,\n",
       "         [-0.4644,  0.1016,  0.5888,  ...,  0.0490,  0.1449, -0.1620],\n",
       "         [-0.7544,  0.0367,  0.5905,  ..., -0.2962,  0.3979, -0.3003],\n",
       "         [-1.0178, -0.2916,  0.8136,  ..., -0.1177,  0.0848, -0.3275]],\n",
       "\n",
       "        [[-0.6159, -0.2392, -1.0298,  ..., -0.8175, -0.6232,  0.5737],\n",
       "         [-0.2113, -0.0386,  0.6628,  ..., -0.6532, -0.5913, -0.0465],\n",
       "         [-0.6121,  0.9621,  0.8437,  ..., -0.9682,  0.2243, -0.9689],\n",
       "         ...,\n",
       "         [-0.3500,  0.3019,  0.4803,  ..., -0.1222,  0.1726,  0.3479],\n",
       "         [-0.7741,  0.0920,  0.4215,  ..., -0.0141,  0.1913,  0.2502],\n",
       "         [-0.5961,  0.3459,  0.5837,  ..., -0.4462,  0.0223, -0.2655]],\n",
       "\n",
       "        [[-0.3607, -0.4403, -0.9392,  ..., -0.9147, -0.1683,  0.5529],\n",
       "         [-0.7109, -1.3708,  0.9034,  ..., -0.7633,  0.6787, -0.1827],\n",
       "         [-0.7970, -1.0461, -0.9818,  ...,  0.0115,  0.4822,  0.2015],\n",
       "         ...,\n",
       "         [-0.1171,  0.1242,  0.8643,  ..., -0.2402,  0.5139,  0.1460],\n",
       "         [-0.3776,  0.3024,  0.7781,  ..., -0.5101,  0.3397, -0.3974],\n",
       "         [-0.5647, -0.0637,  0.8312,  ..., -0.6800,  0.1841, -0.4077]],\n",
       "\n",
       "        [[-0.2706, -0.2999, -1.0336,  ..., -0.8361, -0.2400,  0.3992],\n",
       "         [-0.6391,  0.0889, -0.4309,  ...,  0.2705, -0.5220, -1.4328],\n",
       "         [ 0.2779,  0.2187, -0.4222,  ..., -0.6645,  0.4178, -1.2845],\n",
       "         ...,\n",
       "         [ 0.6009,  0.9094,  0.4355,  ..., -0.0775,  1.3196,  0.0388],\n",
       "         [-0.6857,  0.2647, -0.4554,  ..., -0.3186,  0.0613,  0.3309],\n",
       "         [ 0.0518,  0.0399, -0.0673,  ..., -0.0078,  0.0018, -0.0375]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.6566, -0.2362, -1.0801,  ..., -0.9766,  0.1580,  0.4326],\n",
       "         [-0.1087, -0.8785, -0.6252,  ...,  0.2639, -0.0493, -0.0830],\n",
       "         [-0.5123, -0.4120,  0.4348,  ..., -0.1189,  0.7953, -0.3447],\n",
       "         ...,\n",
       "         [-0.3590,  0.0762,  0.5277,  ..., -0.2237,  0.4091, -0.4872],\n",
       "         [-0.6401,  0.0112,  0.5386,  ..., -0.4843,  0.6870, -0.6015],\n",
       "         [-0.8673, -0.3264,  0.7165,  ..., -0.3063,  0.3516, -0.6618]],\n",
       "\n",
       "        [[-0.7439, -0.0974, -1.0542,  ..., -1.0560, -0.2350,  0.2829],\n",
       "         [-0.1339, -0.2997,  0.6042,  ..., -0.8359, -0.5075,  0.1564],\n",
       "         [-0.3554,  0.7514,  1.5172,  ..., -0.4275,  0.3750, -0.9545],\n",
       "         ...,\n",
       "         [-0.1633,  0.1779,  0.5423,  ..., -0.4354,  0.3256, -0.0335],\n",
       "         [-0.4820,  0.0859,  0.4984,  ..., -0.3006,  0.3172, -0.1095],\n",
       "         [-0.4595,  0.2653,  0.5443,  ..., -0.6567,  0.1336, -0.5771]],\n",
       "\n",
       "        [[-0.4469, -0.3431, -1.1302,  ..., -1.0446,  0.0609,  0.3674],\n",
       "         [-0.6316, -0.7391,  0.5915,  ..., -0.3234,  0.4252, -0.4119],\n",
       "         [-0.6956, -0.4150, -1.1855,  ...,  0.5026,  0.6728, -0.5436],\n",
       "         ...,\n",
       "         [ 0.0488,  0.0293,  0.8573,  ..., -0.4577,  0.6051, -0.3056],\n",
       "         [-0.2118,  0.2872,  0.8538,  ..., -0.5563,  0.5913, -0.8515],\n",
       "         [-0.3806, -0.0210,  0.8394,  ..., -0.7787,  0.4447, -0.8592]],\n",
       "\n",
       "        [[-0.5335, -0.1447, -1.1286,  ..., -1.0121,  0.0479,  0.4798],\n",
       "         [-0.7021,  0.4474, -0.6037,  ...,  0.1229, -0.3130, -0.6873],\n",
       "         [ 0.3844,  0.7395, -0.4589,  ..., -0.5229,  0.2407, -1.0088],\n",
       "         ...,\n",
       "         [ 0.2180,  1.2438,  0.3902,  ..., -0.0732,  1.0269,  0.3326],\n",
       "         [-0.6527,  0.0512, -0.4383,  ..., -0.4910,  0.1037,  0.1936],\n",
       "         [ 0.0613,  0.0687, -0.0391,  ..., -0.0374, -0.0862, -0.0337]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.9203, -0.7286, -0.1007,  ..., -0.4801,  0.4450,  0.0652],\n",
       "         [-0.3600, -1.0586,  0.2559,  ...,  0.3511,  0.4180, -0.3467],\n",
       "         [-0.7044, -0.8509,  0.8785,  ..., -0.3453,  0.8136, -0.5629],\n",
       "         ...,\n",
       "         [-0.5259,  0.1539,  0.9478,  ..., -0.4374,  0.5382, -0.5869],\n",
       "         [-0.8167,  0.0749,  1.0172,  ..., -0.5362,  0.8090, -0.6635],\n",
       "         [-0.9928, -0.2264,  1.1520,  ..., -0.3250,  0.6111, -0.6265]],\n",
       "\n",
       "        [[-1.1364,  0.0554, -0.7486,  ..., -0.6206,  0.1355, -0.0334],\n",
       "         [-0.2013, -0.0663,  0.5897,  ..., -0.6207, -0.3971,  0.1753],\n",
       "         [-0.4864,  0.5717,  1.4220,  ..., -0.2991,  0.7023, -0.8731],\n",
       "         ...,\n",
       "         [-0.3486,  0.1543,  0.8649,  ..., -0.3622,  0.1374, -0.1674],\n",
       "         [-0.6982,  0.1298,  0.8201,  ..., -0.2310,  0.0724, -0.2575],\n",
       "         [-0.5974,  0.2071,  0.8776,  ..., -0.5457, -0.0271, -0.6498]],\n",
       "\n",
       "        [[-0.7277, -0.3211, -0.3442,  ..., -0.8892,  0.3838, -0.0217],\n",
       "         [-0.8887, -0.4721,  1.0006,  ..., -0.2579,  0.2783, -0.4905],\n",
       "         [-0.5469, -0.1943, -0.7857,  ...,  0.2967,  0.3072, -0.5182],\n",
       "         ...,\n",
       "         [-0.0669,  0.2515,  1.0794,  ..., -0.6663,  0.3302, -0.5315],\n",
       "         [-0.2154,  0.4120,  1.0052,  ..., -0.6133,  0.3626, -1.0303],\n",
       "         [-0.3579,  0.0905,  1.0115,  ..., -0.7892,  0.2441, -0.9619]],\n",
       "\n",
       "        [[-0.7995, -0.2561, -0.5977,  ..., -0.5546,  0.3708,  0.0653],\n",
       "         [-0.7051,  0.0810, -0.3199,  ...,  0.5819, -0.0622, -0.6583],\n",
       "         [ 0.4327,  0.4642, -0.6168,  ..., -0.6416,  0.6227, -1.0849],\n",
       "         ...,\n",
       "         [ 0.0296,  0.8186,  0.5547,  ...,  0.3539,  0.7985,  0.2005],\n",
       "         [-0.1014,  0.2044, -0.2174,  ..., -0.2446,  0.0835,  0.0368],\n",
       "         [ 0.0573,  0.1213, -0.0262,  ..., -0.0372, -0.0472,  0.0897]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.9962, -0.5872,  0.3701,  ...,  0.6398,  0.1793, -0.1923],\n",
       "         [-0.8259, -0.8676,  0.6782,  ...,  0.7907,  0.2205, -0.2855],\n",
       "         [-0.9252, -0.6804,  0.9579,  ...,  0.5400,  0.5154, -0.5352],\n",
       "         ...,\n",
       "         [-0.7321, -0.2686,  0.8077,  ...,  0.2268,  0.5559, -0.6373],\n",
       "         [-0.9442, -0.3391,  0.8012,  ...,  0.0947,  0.7741, -0.6449],\n",
       "         [-1.1024, -0.5412,  0.9140,  ...,  0.2702,  0.6751, -0.6643]],\n",
       "\n",
       "        [[-0.4497,  0.7577, -0.7268,  ..., -0.0580, -0.1357, -0.2903],\n",
       "         [ 0.4980,  1.1667,  0.4989,  ..., -0.1256, -0.6526,  0.1746],\n",
       "         [-0.0521,  1.3979,  1.4131,  ..., -0.0592,  0.5347, -0.7601],\n",
       "         ...,\n",
       "         [-0.0516,  0.7142,  0.7679,  ..., -0.2623,  0.1601, -0.0275],\n",
       "         [-0.3517,  0.6532,  0.6837,  ..., -0.2012,  0.0443, -0.1347],\n",
       "         [-0.1830,  0.8996,  0.7127,  ..., -0.3572,  0.0467, -0.4268]],\n",
       "\n",
       "        [[-0.7105, -0.4130,  0.0362,  ...,  0.1613,  0.3337, -0.2193],\n",
       "         [-1.0040, -0.4460,  1.0282,  ...,  0.3180,  0.5164, -0.6105],\n",
       "         [-0.5744, -0.4201, -0.4855,  ...,  0.8740,  0.6682, -0.7292],\n",
       "         ...,\n",
       "         [-0.0542, -0.0248,  0.8811,  ..., -0.2240,  0.3812, -0.5729],\n",
       "         [-0.2295,  0.1062,  0.8368,  ..., -0.2668,  0.4246, -1.0281],\n",
       "         [-0.3919, -0.2167,  0.7949,  ..., -0.3884,  0.3372, -0.9692]],\n",
       "\n",
       "        [[-0.7198, -0.1616, -0.5473,  ...,  0.1692,  0.2095, -0.0955],\n",
       "         [-1.0449, -0.1474, -0.3922,  ...,  0.7107, -0.1335, -0.6346],\n",
       "         [ 0.2747,  0.2028, -1.0055,  ..., -0.2376,  0.5509, -1.0754],\n",
       "         ...,\n",
       "         [ 0.0377,  0.7552,  0.3889,  ...,  0.5837,  0.8052, -0.0792],\n",
       "         [ 0.0095,  0.0452,  0.0403,  ..., -0.0666,  0.0582,  0.0201],\n",
       "         [ 0.0330,  0.0315,  0.0222,  ..., -0.0407,  0.0632,  0.0435]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[-1.0132, -0.8756, -0.2658,  ...,  0.5588, -1.0650, -0.6430],\n",
       "         [-0.9748, -0.9714, -0.0135,  ...,  0.5621, -0.9862, -0.7785],\n",
       "         [-1.0049, -0.8098,  0.0910,  ...,  0.4721, -0.8452, -0.9117],\n",
       "         ...,\n",
       "         [-0.7698, -0.5025,  0.0407,  ...,  0.2064, -0.8134, -0.9489],\n",
       "         [-0.8795, -0.5413, -0.0024,  ...,  0.1687, -0.7145, -0.9865],\n",
       "         [-0.9481, -0.6133,  0.0490,  ...,  0.2739, -0.8090, -0.9951]],\n",
       "\n",
       "        [[-0.1368,  0.6048, -0.7089,  ...,  0.4937,  0.1140, -0.4037],\n",
       "         [ 0.5070,  1.2251,  0.2203,  ...,  0.1685, -0.2644,  0.0565],\n",
       "         [ 0.0790,  1.2887,  0.8892,  ...,  0.0328,  0.5355, -0.6403],\n",
       "         ...,\n",
       "         [ 0.1908,  0.7853,  0.4368,  ..., -0.0573,  0.4684,  0.0441],\n",
       "         [-0.0536,  0.7441,  0.4027,  ..., -0.0663,  0.3998, -0.0622],\n",
       "         [ 0.0480,  0.8959,  0.4508,  ..., -0.1652,  0.3511, -0.2798]],\n",
       "\n",
       "        [[-0.6503, -0.9364, -0.4187,  ...,  0.3339, -0.6352, -0.4508],\n",
       "         [-0.8663, -0.7946,  0.4998,  ...,  0.3316, -0.3517, -0.9355],\n",
       "         [-0.6214, -0.5547, -0.5553,  ...,  0.8049, -0.1166, -1.0115],\n",
       "         ...,\n",
       "         [ 0.0016, -0.2981,  0.3561,  ..., -0.3131, -0.2592, -0.8930],\n",
       "         [-0.1368, -0.1466,  0.2992,  ..., -0.2706, -0.2182, -1.2560],\n",
       "         [-0.2507, -0.4212,  0.2273,  ..., -0.3794, -0.3365, -1.1921]],\n",
       "\n",
       "        [[-0.7815, -0.7668, -0.6248,  ...,  0.5030, -0.3916, -0.2033],\n",
       "         [-1.0727, -0.5209, -0.3181,  ...,  0.4701, -0.3692, -0.6688],\n",
       "         [ 0.1134,  0.0198, -0.9223,  ..., -0.1206,  0.3610, -0.9616],\n",
       "         ...,\n",
       "         [-0.1372,  0.3713,  0.2815,  ...,  0.4748,  0.6915, -0.3377],\n",
       "         [-0.0050, -0.0789, -0.0213,  ...,  0.0089, -0.0389, -0.0273],\n",
       "         [-0.0043, -0.0765, -0.0234,  ...,  0.0103, -0.0378, -0.0200]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.8492, -0.5021,  0.0442,  ...,  0.6306, -0.7022, -0.3212],\n",
       "         [-0.7998, -0.5644,  0.1654,  ...,  0.5703, -0.6205, -0.3455],\n",
       "         [-0.8249, -0.4584,  0.2058,  ...,  0.5077, -0.5489, -0.4317],\n",
       "         ...,\n",
       "         [-0.5328, -0.1932,  0.1661,  ...,  0.2689, -0.3899, -0.3924],\n",
       "         [-0.5822, -0.2077,  0.1231,  ...,  0.2484, -0.3243, -0.4090],\n",
       "         [-0.6514, -0.2240,  0.1484,  ...,  0.3226, -0.3872, -0.4533]],\n",
       "\n",
       "        [[-0.0064,  0.3276, -0.4520,  ...,  0.3182, -0.1312, -0.0526],\n",
       "         [ 0.4304,  0.7200,  0.0995,  ...,  0.0697, -0.3024,  0.2720],\n",
       "         [ 0.1434,  0.9574,  0.7019,  ..., -0.0137,  0.2503, -0.3453],\n",
       "         ...,\n",
       "         [ 0.1309,  0.3501,  0.1913,  ...,  0.0339,  0.2768,  0.1328],\n",
       "         [ 0.0237,  0.3409,  0.1788,  ...,  0.0333,  0.2625,  0.0991],\n",
       "         [ 0.0623,  0.4172,  0.1899,  ..., -0.0122,  0.2315, -0.0035]],\n",
       "\n",
       "        [[-0.5323, -0.7151, -0.0994,  ...,  0.4279, -0.5174, -0.2604],\n",
       "         [-0.5442, -0.5906,  0.4419,  ...,  0.2226, -0.2467, -0.4526],\n",
       "         [-0.2700, -0.4528, -0.2442,  ...,  0.4079, -0.0803, -0.5080],\n",
       "         ...,\n",
       "         [ 0.0470, -0.1286,  0.1892,  ..., -0.0887, -0.0239, -0.3115],\n",
       "         [-0.0199, -0.0577,  0.1463,  ..., -0.0714, -0.0084, -0.4573],\n",
       "         [-0.0815, -0.1759,  0.1173,  ..., -0.1375, -0.0570, -0.4555]],\n",
       "\n",
       "        [[-0.6138, -0.5957, -0.1269,  ...,  0.6685, -0.2748, -0.1292],\n",
       "         [-0.6962, -0.3615, -0.0893,  ...,  0.2796, -0.1569, -0.1432],\n",
       "         [ 0.0556,  0.0563, -0.4818,  ...,  0.0327,  0.3616, -0.4782],\n",
       "         ...,\n",
       "         [-0.0336,  0.2031,  0.1797,  ...,  0.2630,  0.3879, -0.0970],\n",
       "         [ 0.1418, -0.3831, -0.0245,  ...,  0.1267, -0.0517, -0.1260],\n",
       "         [ 0.1422, -0.3832, -0.0269,  ...,  0.1298, -0.0582, -0.1044]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)), attentions=None)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SequenceClassifierOutput' object has no attribute 'sequences'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [67], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtoddbenchmark\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils_classification\u001b[39;00m \u001b[39mimport\u001b[39;00m prepare_detectors\n\u001b[1;32m      2\u001b[0m detectors: List[ScorerType] \u001b[39m=\u001b[39m [\n\u001b[1;32m      3\u001b[0m     MahalanobisScorer(layers\u001b[39m=\u001b[39m[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])]\n\u001b[0;32m----> 5\u001b[0m detectors \u001b[39m=\u001b[39m prepare_detectors(detectors, model, in_val_loader, tokenizer)\n",
      "File \u001b[0;32m~/OOD3/toddbenchmark/utils_classification.py:36\u001b[0m, in \u001b[0;36mprepare_detectors\u001b[0;34m(detectors, model, loader, tokenizer)\u001b[0m\n\u001b[1;32m     33\u001b[0m     output[\u001b[39m'\u001b[39m\u001b[39mencoder_hidden_states\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m output[\u001b[39m'\u001b[39m\u001b[39mhidden_states\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     35\u001b[0m     \u001b[39mfor\u001b[39;00m detector \u001b[39min\u001b[39;00m detectors:\n\u001b[0;32m---> 36\u001b[0m         detector\u001b[39m.\u001b[39;49maccumulate(output)\n\u001b[1;32m     38\u001b[0m \u001b[39mfor\u001b[39;00m detector \u001b[39min\u001b[39;00m detectors:\n\u001b[1;32m     39\u001b[0m     detector\u001b[39m.\u001b[39mfit()\n",
      "File \u001b[0;32m~/OOD3/Todd/featuresscorers.py:39\u001b[0m, in \u001b[0;36mMahalanobisScorer.accumulate\u001b[0;34m(self, output, y)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39maccumulate\u001b[39m(\u001b[39mself\u001b[39m, output: ModelOutput, y: Optional[List[\u001b[39mint\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     31\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[39m    Accumulate the embeddings of the input sequences in the scorer. To be used before fitting\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[39m    the scorer with self.fit.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39m    @param y: classes of the input sequences (used to build per class references)\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mextract_batch_embeddings(\n\u001b[1;32m     40\u001b[0m         output\u001b[39m=\u001b[39;49moutput,\n\u001b[1;32m     41\u001b[0m         y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m     42\u001b[0m     )\n",
      "File \u001b[0;32m~/OOD3/Todd/basescorers.py:116\u001b[0m, in \u001b[0;36mHiddenStateBasedScorers.extract_batch_embeddings\u001b[0;34m(self, output, y)\u001b[0m\n\u001b[1;32m    114\u001b[0m layers \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers\n\u001b[1;32m    115\u001b[0m \u001b[39m# Update accumulation device if needed\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccumulation_device \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39;49msequences[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mdevice\n\u001b[1;32m    118\u001b[0m \u001b[39m# TODO: Check non-breaking; I removed it for clarity\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[39m# if layers is None:\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[39m#     layers = range(len(data))\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[39m#     N_layers = len(data)\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39m#     layers = [l if l >= 0 else N_layers + l for l in layers]\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m layers:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SequenceClassifierOutput' object has no attribute 'sequences'"
     ]
    }
   ],
   "source": [
    "from toddbenchmark.utils_classification import prepare_detectors\n",
    "detectors: List[ScorerType] = [\n",
    "    MahalanobisScorer(layers=[-1])]\n",
    "\n",
    "detectors = prepare_detectors(detectors, model, in_val_loader, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
